import requests
from bs4 import BeautifulSoup
import tweepy

# Function to scrape news from a given URL
def scrape_news(url):
    response = requests.get(url)
    soup = BeautifulSoup(response.text, 'html.parser')
    news_text = ''
    # Extract text from relevant elements
    for element in soup.find_all(['p', 'h1', 'h2', 'h3', 'h4', 'h5', 'h6']):
        news_text += element.get_text() + ' '
    return news_text.strip()

def scrape_twitter(api_key, api_secret_key, access_token, access_token_secret, query):
    auth = tweepy.OAuth1UserHandler(api_key, api_secret_key, access_token, access_token_secret)
    api = tweepy.API(auth)
    tweets = api.search(q=query, count=10)
    twitter_text = ''
    for tweet in tweets:
        twitter_text += tweet.text + ' '
    return twitter_text.strip()

# Main function to fetch news from various sources
def fetch_latest_news():
    news_sources = [
        'https://twitter.com/search?q=Reliance%20Industries%20Ltd&src=typed_query&f=live',
        'https://timesofindia.indiatimes.com/topic/Reliance-Industries',
        'https://www.moneycontrol.com/news/business/stocks/reliance-industries-stock-price-ri-1594.html',
        # Add more news websites URLs as needed
    ]


    api_key = 'your_api_key'
    api_secret_key = 'your_api_secret_key'
    access_token = 'your_access_token'
    access_token_secret = 'your_access_token_secret'

    news_data = []


    for source in news_sources:
        if 'twitter.com' in source:
            text = scrape_twitter(api_key, api_secret_key, access_token, access_token_secret, 'Reliance Industries Ltd')
        else:
            text = scrape_news(source)
        news_data.append({'source': source, 'text': text})

    return news_data

latest_news = fetch_latest_news()
for news in latest_news:
    print(news)
